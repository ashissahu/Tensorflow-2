{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CONVOLUTIONAL NEURAL NETWORK using Tensorflow 2.0**\n",
    "In this scenario of hands-on, you will be performing Convolutional Neural Network using Tensorflow 2.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the below cell to import the neccessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "#from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assign the value as 100 to the variabel **RANDOM_SEED** which will be the seed value.\n",
    "- Set the random seed value using the value stored in the variable **RANDOM_SEED**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED =100\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the dataset using  **load_data** function and save it in variables **x_train**,**y_train**,**x_test** and **y_test** respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) =load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determine the shape of the input images for training data (i.e) **x_train** and save it in variable **in_shape**.\n",
    "- Determine the number of classes of the input data using the variable **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# determine the shape of the input images\n",
    "in_shape = x_train.shape[1:]\n",
    "print(in_shape)\n",
    "# determine the number of classes\n",
    "n_classes = len(unique(y_train))\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "- Convert the data type of **x_train** and **x_test** to **float32** and normalize it by dividing it by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "\n",
    "Construct a fully-connected network structure defined using dense class\n",
    "- Create a sequential model\n",
    "- Add a Convolutional layer which has 128 nodes with input shape as (3,3) , activation function as relu and input shape as **in_shape**.\n",
    "- Add a MaxPool Layer with shape as (2,2).\n",
    "- Add a Flatten Layer as output of convolutional layer.\n",
    "- Add a hidden layer which has 150 nodes and uses the relu activation function.\n",
    "- Add a dropout layer with dropout rate as 0.5\n",
    "- The output layer has the number of nodes as **n_classes** and uses the softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(150, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model\n",
    "- While comipling the model pass the following parameters -\n",
    "                    \n",
    "           -optimizer as adam\n",
    "           -loss as sparse categorical cross entropy \n",
    "           -metrics as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "- fit the model with X_train, y_train, epochs=10, batch_size=128,verbose=0.\n",
    "\n",
    "**Note** - Here this might take upto 10-15 mins to run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f06d46b70f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict model\n",
    "- Perform prediction on the test data (i.e) on **X_test** and save the predictions in the variable **y_pred**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cell to convert the predictions to argmax (i.e) to return the indices of the maximum values along each axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=[]\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred1.append(argmax(y_pred[i]))\n",
    "count=0\n",
    "for act, pred in zip(y_test, y_pred1):\n",
    "        if act == pred:\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the accuracy score on the variables **y_test** and **y_pred1** using the accuracy_score function in sklearn and save it in variable **acc**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.649 \n"
     ]
    }
   ],
   "source": [
    "acc =accuracy_score(y_test,y_pred1)\n",
    "print('Accuracy Score: %.3f ' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the F1 score on the variables **y_test** and **y_pred1** using the f1_score function in sklearn with average as weighted and save it in variable **f1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.649 \n"
     ]
    }
   ],
   "source": [
    "f1 =f1_score(y_test,y_pred1,average='weighted')\n",
    "print('F1 Score: %.3f ' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cells to save the results for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Accuracy.txt\", \"w\") as text_file:\n",
    "        acc=str(acc)\n",
    "        text_file.write(acc)\n",
    "with open(\"F1.txt\", \"w\") as text_file:\n",
    "        f1=str(f1)\n",
    "        text_file.write(f1)\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
